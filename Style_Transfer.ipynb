{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import vgg19\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Images #\n",
    "\n",
    "I chose a random golden gate bridge image, 'content.jpg'. I used that impressionist's painting, 'style.jpg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIMS = [200,350]\n",
    "style_image = scipy.misc.imresize(scipy.misc.imread('style.jpg'), DIMS)\n",
    "plt.figure()\n",
    "imshow(style_image)\n",
    "content_image = scipy.misc.imresize(scipy.misc.imread('content.jpg'), DIMS)\n",
    "plt.figure()\n",
    "imshow(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VGG_MEAN = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "data_dict = np.load('vgg19.npy', encoding='latin1').item()\n",
    "print (VGG_MEAN.shape)\n",
    "print (style_image.shape)\n",
    "style_image = style_image - VGG_MEAN\n",
    "plt.figure()\n",
    "imshow(style_image[0])\n",
    "content_image = content_image - VGG_MEAN\n",
    "plt.figure()\n",
    "imshow(content_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(data_dict.keys())\n",
    "# We can see that [0] is the weights, and [1] is the biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _weights(data_dict, layer):\n",
    "    \"\"\" Returns the weights in TF constant form \"\"\"\n",
    "    return tf.constant(data_dict[layer][0]), tf.constant(data_dict[layer][1])\n",
    "def _conv(data_dict, prev_layer, layer):\n",
    "    W,b = _weights(data_dict, layer)\n",
    "    \"\"\" Returns a convolution filter activation with standard strides \"\"\"\n",
    "    return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "def _conv_relu(data_dict, prev_layer, layer):\n",
    "    \"\"\" Does both relu and conv \"\"\"\n",
    "    return tf.nn.relu(_conv(data_dict, prev_layer, layer))\n",
    "def _pool(layer):\n",
    "    \"\"\" pools with standard strides. avg_pool does better for style transfer according to Gatys et al. \"\"\"\n",
    "    return tf.nn.avg_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = [1, *DIMS, 3]\n",
    "x = tf.Variable(np.zeros(input_shape, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1_1 = _conv_relu(data_dict, x, 'conv1_1')\n",
    "conv1_2 = _conv_relu(data_dict, conv1_1, 'conv1_2')\n",
    "pool1 = _pool(conv1_2)\n",
    "\n",
    "conv2_1 = _conv_relu(data_dict, pool1, 'conv2_1')\n",
    "conv2_2 = _conv_relu(data_dict, conv2_1, 'conv2_2')\n",
    "pool2 = _pool(conv2_2)\n",
    "\n",
    "conv3_1 = _conv_relu(data_dict, pool2, 'conv3_1')\n",
    "conv3_2 = _conv_relu(data_dict, conv3_1, 'conv3_2')\n",
    "conv3_3 = _conv_relu(data_dict, conv3_2, 'conv3_3')\n",
    "conv3_4 = _conv_relu(data_dict, conv3_3, 'conv3_4')\n",
    "pool3 = _pool(conv3_4)\n",
    "\n",
    "conv4_1 = _conv_relu(data_dict, pool3, 'conv4_1')\n",
    "conv4_2 = _conv_relu(data_dict, conv4_1, 'conv4_2')\n",
    "conv4_3 = _conv_relu(data_dict, conv4_2, 'conv4_3')\n",
    "conv4_4 = _conv_relu(data_dict, conv4_3, 'conv4_4')\n",
    "pool4 = _pool(conv4_4)\n",
    "\n",
    "conv5_1 = _conv_relu(data_dict, pool4, 'conv5_1')\n",
    "conv5_2 = _conv_relu(data_dict, conv5_1, 'conv5_2')\n",
    "conv5_3 = _conv_relu(data_dict, conv5_2, 'conv5_3')\n",
    "conv5_4 = _conv_relu(data_dict, conv5_3, 'conv5_4')\n",
    "\n",
    "\n",
    "# From Gatys et al. :\n",
    "# \"The images were synthesized by matching content representation on layer 'conv4_2',... \n",
    "# style on layers 'conv1_1','conv2_1','conv3_1','conv4_1','conv5_1'.\"\n",
    "# Let's use what they prescribed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer #\n",
    "\n",
    "The style transfer paper: \n",
    "\n",
    "$L_{total}(p,a,x) = \\alpha L_{content}(p,x) + \\beta L_{style}(a,x) = \\alpha (\\frac{1}{2}\\sum_{i,j}(P_{ij}^l-F_{ij}^l)^2)) + \\beta (\\sum_lw_lE_l)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_LAYER = conv4_2\n",
    "STYLE_LAYERS = (conv1_1, conv2_1, conv3_1, conv4_1, conv5_1) \n",
    "STYLE_WEIGHTS = (0.5,1.,1.5,3.,4.)\n",
    "alpha = 100\n",
    "beta = 5\n",
    "ITERS = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize(content_image):\n",
    "    return np.reshape((np.random.rand(*input_shape)*150-75) * 0.5 + (content_image[0]) * 0.5, content_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_content(p):\n",
    "    N = p.shape[3]\n",
    "    M = p.shape[1]*p.shape[2]\n",
    "    L = tf.reduce_sum(tf.pow((p-CONTENT_LAYER),2)) / (2 * N * M)\n",
    "    return L\n",
    "\n",
    "def L_style_layer(a, x):\n",
    "    N = a.shape[3]\n",
    "    M = a.shape[1]*a.shape[2]\n",
    "    _x = tf.reshape(x, [M, N])\n",
    "    _a = tf.reshape(a, [M, N])\n",
    "    G = tf.matmul(tf.transpose(_x), _x)\n",
    "    A = tf.matmul(tf.transpose(_a), _a)\n",
    "    L = tf.reduce_sum(tf.pow((G-A), 2)) / (4 * N**2 * M**2)\n",
    "    return L\n",
    "\n",
    "def L_style(a, w):\n",
    "    L = 0\n",
    "    for i, style in enumerate(STYLE_LAYERS):\n",
    "        L += w[i]*L_style_layer(a[i], style)\n",
    "    return L\n",
    "\n",
    "def L(a, p, w):\n",
    "    return alpha * L_content(p) + beta * L_style(a, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A quick look at initialize()\n",
    "im = np.array(np.minimum(np.maximum((initialize(content_image) + VGG_MEAN)[0], 0), 255), dtype=np.uint8)\n",
    "imshow(im)\n",
    "print(np.min(im), np.max(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Run the Op that initializes global variables.\n",
    "    sess.run(x.assign(content_image))\n",
    "    content = sess.run(conv4_2)\n",
    "    sess.run(x.assign(style_image))\n",
    "    style = [sess.run(style) for style in STYLE_LAYERS]\n",
    "    for s in style:\n",
    "        print(s.shape)\n",
    "    loss = L(style, content, STYLE_WEIGHTS)\n",
    "    train_op = tf.train.AdamOptimizer(2.).minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(x.assign(initialize(content_image)))\n",
    "    for i in range(ITERS):\n",
    "        sess.run(train_op)\n",
    "        if i % 10 == 0:\n",
    "            print('cost at the ', i,' -th iter: ', sess.run(loss))\n",
    "        if i % 100 == 0:\n",
    "            image = np.array(np.minimum(np.maximum((sess.run(x) + VGG_MEAN)[0], 0), 255), dtype=np.uint8)\n",
    "            scipy.misc.imsave('out.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
